{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfAI/nlp00/blob/master/09%20-%20Word%20embedding%20e%20Word2Vec/word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KprtIuKVksZF",
        "colab_type": "text"
      },
      "source": [
        "# Il Word2Vec\n",
        "Il **Word2Vec** è un metodo che ci permette di creare una rappresentazione vettoriale delle parole (**word embedding**) usando il deep learning.  Google mette a disposizione un modello preaddestrato su un corpus di Google News, contenente 3 milioni di parole e 300 dimensioni. Possiamo scaricare il modello preaddestrato da [questo link](https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz).\n",
        "<br><br>\n",
        "Se utilizzi Google Colab o comunque hai wget installato sul tuo computer esegui pure la cella di codice qui sotto per scaricare il dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qLzv-tDUYHa",
        "colab_type": "code",
        "outputId": "76d98278-7876-4e24-e3f4-d169af507f42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "!wget https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-03 14:01:20--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.106.85\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.106.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  50.2MB/s    in 27s     \n",
            "\n",
            "2019-05-03 14:01:47 (58.7 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu-yv8ttmIXE",
        "colab_type": "text"
      },
      "source": [
        "Ed estrai il file .gz utilizzando gunzip."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vodVGN_Ug8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gunzip GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVTpHydnmNYh",
        "colab_type": "text"
      },
      "source": [
        "In questo notebook useremo **gensim** per caricare il modello preaddestrato, per farlo ci basta usare la funzione *.load_word2vec_format(filpath)*, trattandosi di un file binario dobbiamo specificare il parametro *binary* a true."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sliNG3G7Ureu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f672ca16-07fc-4a9f-cef2-dff9d45514cf"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "import gensim\n",
        "\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
        "type(model)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gensim.models.keyedvectors.Word2VecKeyedVectors"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxDCro_1mh8E",
        "colab_type": "text"
      },
      "source": [
        "Possiamo accedere alla rappresentazione vettoriale di una parola utilizzando l'oggetto model come se fosse un dizionario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWTDpWvIWmGo",
        "colab_type": "code",
        "outputId": "6567b2d5-b064-4565-b6ec-12e65541b99a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        }
      },
      "source": [
        "print(model[\"man\"].shape)\n",
        "print(model[\"man\"])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(300,)\n",
            "[ 0.32617188  0.13085938  0.03466797 -0.08300781  0.08984375 -0.04125977\n",
            " -0.19824219  0.00689697  0.14355469  0.0019455   0.02880859 -0.25\n",
            " -0.08398438 -0.15136719 -0.10205078  0.04077148 -0.09765625  0.05932617\n",
            "  0.02978516 -0.10058594 -0.13085938  0.001297    0.02612305 -0.27148438\n",
            "  0.06396484 -0.19140625 -0.078125    0.25976562  0.375      -0.04541016\n",
            "  0.16210938  0.13671875 -0.06396484 -0.02062988 -0.09667969  0.25390625\n",
            "  0.24804688 -0.12695312  0.07177734  0.3203125   0.03149414 -0.03857422\n",
            "  0.21191406 -0.00811768  0.22265625 -0.13476562 -0.07617188  0.01049805\n",
            " -0.05175781  0.03808594 -0.13378906  0.125       0.0559082  -0.18261719\n",
            "  0.08154297 -0.08447266 -0.07763672 -0.04345703  0.08105469 -0.01092529\n",
            "  0.17480469  0.30664062 -0.04321289 -0.01416016  0.09082031 -0.00927734\n",
            " -0.03442383 -0.11523438  0.12451172 -0.0246582   0.08544922  0.14355469\n",
            " -0.27734375  0.03662109 -0.11035156  0.13085938 -0.01721191 -0.08056641\n",
            " -0.00708008 -0.02954102  0.30078125 -0.09033203  0.03149414 -0.18652344\n",
            " -0.11181641  0.10253906 -0.25976562 -0.02209473  0.16796875 -0.05322266\n",
            " -0.14550781 -0.01049805 -0.03039551 -0.03857422  0.11523438 -0.0062561\n",
            " -0.13964844  0.08007812  0.06103516 -0.15332031 -0.11132812 -0.14160156\n",
            "  0.19824219 -0.06933594  0.29296875 -0.16015625  0.20898438  0.00041771\n",
            "  0.01831055 -0.20214844  0.04760742  0.05810547 -0.0123291  -0.01989746\n",
            " -0.00364685 -0.0135498  -0.08251953 -0.03149414  0.00717163  0.20117188\n",
            "  0.08300781 -0.0480957  -0.26367188 -0.09667969 -0.22558594 -0.09667969\n",
            "  0.06494141 -0.02502441  0.08496094  0.03198242 -0.07568359 -0.25390625\n",
            " -0.11669922 -0.01446533 -0.16015625 -0.00701904 -0.05712891  0.02807617\n",
            " -0.09179688  0.25195312  0.24121094  0.06640625  0.12988281  0.17089844\n",
            " -0.13671875  0.1875     -0.10009766 -0.04199219 -0.12011719  0.00524902\n",
            "  0.15625    -0.203125   -0.07128906 -0.06103516  0.01635742  0.18261719\n",
            "  0.03588867 -0.04248047  0.16796875 -0.15039062 -0.16992188  0.01831055\n",
            "  0.27734375 -0.01269531 -0.0390625  -0.15429688  0.18457031 -0.07910156\n",
            "  0.09033203 -0.02709961  0.08251953  0.06738281 -0.16113281 -0.19628906\n",
            " -0.15234375 -0.04711914  0.04760742  0.05908203 -0.16894531 -0.14941406\n",
            "  0.12988281  0.04321289  0.02624512 -0.1796875  -0.19628906  0.06445312\n",
            "  0.08935547  0.1640625  -0.03808594 -0.09814453 -0.01483154  0.1875\n",
            "  0.12792969  0.22753906  0.01818848 -0.07958984 -0.11376953 -0.06933594\n",
            " -0.15527344 -0.08105469 -0.09277344 -0.11328125 -0.15136719 -0.08007812\n",
            " -0.05126953 -0.15332031  0.11669922  0.06835938  0.0324707  -0.33984375\n",
            " -0.08154297 -0.08349609  0.04003906  0.04907227 -0.24121094 -0.13476562\n",
            " -0.05932617  0.12158203 -0.34179688  0.16503906  0.06176758 -0.18164062\n",
            "  0.20117188 -0.07714844  0.1640625   0.00402832  0.30273438 -0.10009766\n",
            " -0.13671875 -0.05957031  0.0625     -0.21289062 -0.06542969  0.1796875\n",
            " -0.07763672 -0.01928711 -0.15039062 -0.00106049  0.03417969  0.03344727\n",
            "  0.19335938  0.01965332 -0.19921875 -0.10644531  0.01525879  0.00927734\n",
            "  0.01416016 -0.02392578  0.05883789  0.02368164  0.125       0.04760742\n",
            " -0.05566406  0.11572266  0.14746094  0.1015625  -0.07128906 -0.07714844\n",
            " -0.12597656  0.0291748   0.09521484 -0.12402344 -0.109375   -0.12890625\n",
            "  0.16308594  0.28320312 -0.03149414  0.12304688 -0.23242188 -0.09375\n",
            " -0.12988281  0.0135498  -0.03881836 -0.08251953  0.00897217  0.16308594\n",
            "  0.10546875 -0.13867188 -0.16503906 -0.03857422  0.10839844 -0.10498047\n",
            "  0.06396484  0.38867188 -0.05981445 -0.0612793  -0.10449219 -0.16796875\n",
            "  0.07177734  0.13964844  0.15527344 -0.03125    -0.20214844 -0.12988281\n",
            " -0.10058594 -0.06396484 -0.08349609 -0.30273438 -0.08007812  0.02099609]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ75Nonomo8f",
        "colab_type": "text"
      },
      "source": [
        "Calcolando la **cosine similarity** tra le rappresentazioni vettoriali di due parole possiamo sapere quanto esse sono simili.\n",
        "<br>\n",
        "**NOTA BENE**\n",
        "<br>\n",
        "La funzione *cosine(u,v)* di scipy calcola la distanza del coseno, possiamo trasformare la distanza in similitudine sottrando tale distanza a 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDZ9AYKEa8KO",
        "colab_type": "code",
        "outputId": "c73971bf-6572-465e-8a09-ee31e5d1cd16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "1-cosine(model[\"man\"],model[\"boy\"])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6824870705604553"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9TDXWzinW5A",
        "colab_type": "text"
      },
      "source": [
        "L'oggetto BOH ha il metodo *.similarity(word1, word2)* già implementato per il calcolo diretto della similitudine di due parole."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPmc3PsoVNLM",
        "colab_type": "code",
        "outputId": "d99169f3-6a23-4197-dacb-79974163e706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "print(model.similarity(\"man\",\"boy\")) # queste parole sono molto simili\n",
        "print(model.similarity(\"pizza\",\"mouse\")) # queste parole sono molto diverse (o almeno spero che lo siano)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.68248713\n",
            "0.042691886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0ZCreGvYzOE",
        "colab_type": "text"
      },
      "source": [
        "**ATTENZIONE**\n",
        "<br>\n",
        "Le celle di codice che seguono necessitano di molta RAM e fanno crashare Google Colaboratory, eseguile in locale se hai un PC con almeno 8 gb di RAM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbn2vbuenmcy",
        "colab_type": "text"
      },
      "source": [
        "Possiamo cercare le parole più simili ad una nostra parola chiave usando il metodo *.most_similar*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg_obKSuZyke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model.most_similar(positive=['shocked'], topn=10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h99PSXVjn4HD",
        "colab_type": "text"
      },
      "source": [
        "Utilizzando questo stesso metodo possiamo anche eseguire ricerche più complesse, come le parole più simili a delle determinate parole chiave, passate all'interno del parametro *positive* ma contrarie ad altre parole chiave, passate all'interno del parametro *negative*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81DI8i4GAMOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model.most_similar(positive=['woman', 'king'], negative=['man']))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epJq20ZDoKJ7",
        "colab_type": "text"
      },
      "source": [
        "Un'altro metodo utile è *.doesnt_match(words)* che prendendo in input una serie di parole ritorna quella meno attinente alle altre."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0nkCxoqX4LU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}