{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatbot_seq2seq.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfAI/nlp00/blob/master/8%20-%20Chatbot/chatbot_seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4JI1tKyAjT66",
        "colab_type": "code",
        "outputId": "097cc718-0ba7-4a9e-cf7e-09d707dfa121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-18 14:56:38--  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.20\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.20|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9916637 (9.5M) [application/zip]\n",
            "Saving to: ‘cornell_movie_dialogs_corpus.zip’\n",
            "\n",
            "cornell_movie_dialo 100%[===================>]   9.46M  3.10MB/s    in 3.1s    \n",
            "\n",
            "2019-04-18 14:56:46 (3.10 MB/s) - ‘cornell_movie_dialogs_corpus.zip’ saved [9916637/9916637]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gTbFKg-Ej3-E",
        "colab_type": "code",
        "outputId": "9560203b-7cf7-45b4-840f-41fef14cdb33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip cornell_movie_dialogs_corpus.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cornell_movie_dialogs_corpus.zip\n",
            "   creating: cornell movie-dialogs corpus/\n",
            "  inflating: cornell movie-dialogs corpus/.DS_Store  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/cornell movie-dialogs corpus/\n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._.DS_Store  \n",
            "  inflating: cornell movie-dialogs corpus/chameleons.pdf  \n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._chameleons.pdf  \n",
            "  inflating: cornell movie-dialogs corpus/movie_characters_metadata.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_conversations.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_lines.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_titles_metadata.txt  \n",
            "  inflating: cornell movie-dialogs corpus/raw_script_urls.txt  \n",
            "  inflating: cornell movie-dialogs corpus/README.txt  \n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._README.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "anYbp1HGkYh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05b30e55-90f7-4c0e-b69a-0f130680b30b"
      },
      "cell_type": "code",
      "source": [
        "with open(\"cornell movie-dialogs corpus/movie_lines.txt\", encoding=\"ISO-8859-1\") as file:\n",
        "  lines = file.read().split(\"\\n\")\n",
        "  \n",
        "len(lines)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "304714"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "KFQwyi6g93QO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "1294a0db-5c3d-4425-b85f-281df6af3367"
      },
      "cell_type": "code",
      "source": [
        "for i,line in enumerate(lines):\n",
        "  print(line)\n",
        "  if(i>=10):\n",
        "    break"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
            "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
            "L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n",
            "L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n",
            "L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\n",
            "L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\n",
            "L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\n",
            "L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\n",
            "L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I'm kidding.  You know how sometimes you just become this \"persona\"?  And you don't know how to quit?\n",
            "L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\n",
            "L868 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ The \"real you\".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BRaORWtN-F51",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lines_dict = {}\n",
        "\n",
        "for i,line in enumerate(lines):\n",
        "  try:\n",
        "    if(len(line)>0):\n",
        "      line_key = int(line.split()[0][1:])\n",
        "      line_value = line.split(\" +++$+++ \")[-1]\n",
        "      lines_dict[line_key] = line_value\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    print(lines[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qn0zX6fUJ9dv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06577fef-fd2d-4edc-ad6f-2ddb64f06521"
      },
      "cell_type": "code",
      "source": [
        "lines_dict[1045]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'They do not!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "Q8HAfEWtCGZt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lines_list = sorted(lines_dict.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vxNBmYRSLwEj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "c0278978-19d9-47e5-c797-3927f4045a64"
      },
      "cell_type": "code",
      "source": [
        "lines_list[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(49, 'Did you change your hair?'),\n",
              " (50, 'No.'),\n",
              " (51, 'You might wanna think about it'),\n",
              " (59, 'I missed you.'),\n",
              " (60, 'It says here you exposed yourself to a group of freshmen girls.'),\n",
              " (61, 'It was a bratwurst.  I was eating lunch.'),\n",
              " (62, 'With the teeth of your zipper?'),\n",
              " (63, 'You the new guy?'),\n",
              " (64, 'So they tell me...'),\n",
              " (65, \"C'mon.  I'm supposed to give you the tour.\")]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "LXqb4cZqCWn3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "context = []\n",
        "target = []\n",
        "\n",
        "for i in range(1,len(lines_list)):\n",
        "  \n",
        "  current_line = lines_list[i]\n",
        "  prev_line = lines_list[i-1]\n",
        "    \n",
        "  if(current_line[0]-1==prev_line[0]):\n",
        "    context.append(prev_line[1])\n",
        "    target.append(current_line[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cIzKSfsIM-HZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "87125138-5076-41e2-9239-304988a13b0d"
      },
      "cell_type": "code",
      "source": [
        "context[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Did you change your hair?',\n",
              " 'No.',\n",
              " 'I missed you.',\n",
              " 'It says here you exposed yourself to a group of freshmen girls.',\n",
              " 'It was a bratwurst.  I was eating lunch.',\n",
              " 'With the teeth of your zipper?',\n",
              " 'You the new guy?',\n",
              " 'So they tell me...',\n",
              " \"C'mon.  I'm supposed to give you the tour.\",\n",
              " 'So -- which Dakota you from?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "IapOd1txNIcV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "8fc81c5c-c0ee-47ca-e46a-3ff8fb3dd42d"
      },
      "cell_type": "code",
      "source": [
        "target[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['No.',\n",
              " 'You might wanna think about it',\n",
              " 'It says here you exposed yourself to a group of freshmen girls.',\n",
              " 'It was a bratwurst.  I was eating lunch.',\n",
              " 'With the teeth of your zipper?',\n",
              " 'You the new guy?',\n",
              " 'So they tell me...',\n",
              " \"C'mon.  I'm supposed to give you the tour.\",\n",
              " 'So -- which Dakota you from?',\n",
              " \"North, actually.  How'd you   ?\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "9QjT9K1UNMw3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import string\n",
        "import re\n",
        "\n",
        "def preprocess(text):\n",
        "    \n",
        "  text = text.lower()\n",
        "  text = re.sub(r'[^\\w\\s]','',text)\n",
        "  #text = text.translate(string.punctuation)\n",
        "      \n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9PQukc2rTPS_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c44ad3ee-e868-4535-fcfa-a9e664822a36"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "X = [preprocess(c) for c in context]\n",
        "Y = [preprocess(t) for t in target]\n",
        "\n",
        "print(X[0])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "did you change your hair\n",
            "CPU times: user 1.51 s, sys: 9.9 ms, total: 1.52 s\n",
            "Wall time: 1.52 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "imizOHZhk2Wy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "614e4a12-2e04-4e43-b8ec-6006187b96da"
      },
      "cell_type": "code",
      "source": [
        "dictionary = set({})\n",
        "\n",
        "for x in X:\n",
        "  dictionary|=set(x.split())\n",
        "  \n",
        "for y in Y:\n",
        "  dictionary|=set(y.split())\n",
        "  \n",
        "dictionary = list(dictionary)\n",
        "len(dictionary)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65720"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "RZ2ShP6Dn5Uc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b99fdd20-7a61-47db-92b4-f95068591668"
      },
      "cell_type": "code",
      "source": [
        "dictionary_rev = {k: v for k, v in zip(dictionary, range(len(dictionary)))}\n",
        "dictionary_rev[\"did\"]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52325"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "kgBucJ2Clok0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1be1efa3-e925-44aa-b4fd-2c87506a6e17"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "for i,x in enumerate(X):\n",
        "  X[i] = [dictionary_rev[word] for word in x.split()]\n",
        "  \n",
        "for i,y in enumerate(Y):\n",
        "  Y[i] = [dictionary_rev[word] for word in y.split()]\n",
        "  \n",
        "print(X[0])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[52325, 43331, 40943, 22214, 32544]\n",
            "CPU times: user 3.49 s, sys: 134 ms, total: 3.63 s\n",
            "Wall time: 3.63 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wwnFqRWGhKbY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11f6de12-3770-4a74-f7d4-1f2e3c8ab3ee"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X = pad_sequences(X)\n",
        "Y = pad_sequences(Y)\n",
        "\n",
        "X.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(261177, 477)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "SGw99epjTayN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import model\n",
        "from keras.layers import Embedding, LSTM, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(num_words, 100))\n",
        "model.add(LSTM(32, dropout=0.5, recurrent_dropout=0.2, return_sequences=True))\n",
        "model.add(LSTM(32, dropout=0.5, recurrent_dropout=0.2))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NYJSyAAnqkGw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "72147f2a-46be-4824-bf95-7472723af8f4"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding\n",
        "from keras.layers import Input, Dense, LSTM, TimeDistributed\n",
        "from keras.models import Model\n",
        "\n",
        "vocab_size = len(dictionary)\n",
        "maxLen = 20\n",
        "\n",
        "\n",
        "# load the pre-trained GloVe vectors into the embedding layer\n",
        "embed_layer = Embedding(input_dim = vocab_size, output_dim = 50, trainable = True)\n",
        "embed_layer.build((None,))\n",
        "#embed_layer.set_weights([embedding_atrix])\n",
        "\n",
        "# encoder and decoder gloabal LSTM variables with 300 units\n",
        "LSTM_cell = LSTM(300, return_state = True)\n",
        "LSTM_decoder = LSTM(300, return_state = True, return_sequences = True)\n",
        "# final dense layer that uses TimeDistributed wrapper to generate 'vocab_size' softmax outputs for each time step in the decoder lstm\n",
        "dense = TimeDistributed(Dense(vocab_size, activation = 'softmax'))\n",
        "\n",
        "input_context = Input(shape = (maxLen, ), dtype = 'int32', name = 'input_context')\n",
        "input_target = Input(shape = (maxLen, ), dtype = 'int32', name = 'input_target')\n",
        "\n",
        "# pass the inputs into the embedding layer\n",
        "input_ctx_embed = embed_layer(input_context)\n",
        "input_tar_embed = embed_layer(input_target)\n",
        "\n",
        "# pass the embeddings into the corresponding LSTM layers\n",
        "encoder_lstm, context_h, context_c = LSTM_cell(input_ctx_embed)\n",
        "# the decoder lstm uses the final states from the encoder lstm as the initial state\n",
        "decoder_lstm, _, _ = LSTM_decoder(input_tar_embed, initial_state = [context_h, context_c],)\n",
        "\n",
        "output = dense(vocab_size, activation = 'softmax')(decoder_lstm)\n",
        "\n",
        "model = Model([input_context, input_target], output)\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "model.fit([X, Y], outs, epochs = 10, batch_size = 128)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    473\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[0;32m--> 474\u001b[0;31m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m                          'Expected a symbolic tensor instance.')\n",
            "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'int'>`. Expected a symbolic tensor instance.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-82e2f96db6c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mdecoder_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tar_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcontext_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_lstm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_target\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    283\u001b[0m                                  \u001b[0;34m'Received type: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full input: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. All inputs to the layer '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m                                  'should be tensors.')\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Layer time_distributed_1 was called with an input that isn't a symbolic tensor. Received type: <class 'int'>. Full input: [65720]. All inputs to the layer should be tensors."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "CP6vhdlerMha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}